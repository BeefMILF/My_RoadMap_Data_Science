{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source activate cs231n\n",
    "source deactivate cs231n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.random.rand(10,1)\n",
    "X = np.random.rand(10,2)\n",
    "X.shape, y.shape\n",
    "X1 = np.random.rand(10,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Knearest_classifier:\n",
    "    #def __init__(self):\n",
    "        #pass\n",
    "    \n",
    "    def train(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def test(self, X):\n",
    "        \n",
    "        num = X.shape[0]\n",
    "        \n",
    "        Pred = np.zeros(num, dtype=self.y.dtype)\n",
    "        \n",
    "        for i in range(num):\n",
    "            \n",
    "            distance = np.sum(np.abs(self.X - X[i,:]), axis=1)\n",
    "            \n",
    "            min_distance = np.argmin(distance)\n",
    "            \n",
    "            Pred[i] = self.y[min_distance]\n",
    "            \n",
    "        return Pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Knearest_classifier()\n",
    "d.train(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.76919799, 0.54082469, 0.26826426, 0.73303072, 0.00733151,\n",
       "       0.89609054, 0.20920713, 0.8413235 , 0.48788662, 0.88460406])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.test(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function and "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lecture 6 Trainning CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.02770041e+03 2.13184958e+00 6.53611063e+04 1.82194433e-05\n",
      " 2.79366120e-05 4.77287245e+01 3.18520021e+03 7.31658661e-02\n",
      " 5.80733079e+02 1.46389348e+04]\n"
     ]
    }
   ],
   "source": [
    "count = 10\n",
    "for i in range(count):\n",
    "    rt = 10**np.random.uniform(-5,5,10) # unifrom distribution \n",
    "print(rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SVM loss function in two form unvectorized and vectorised "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_i(x, y, W):\n",
    "  \"\"\"\n",
    "  unvectorized version. Compute the multiclass svm loss for a single example (x,y)\n",
    "  - x is a column vector representing an image (e.g. 3073 x 1 in CIFAR-10)\n",
    "    with an appended bias dimension in the 3073-rd position (i.e. bias trick)\n",
    "  - y is an integer giving index of correct class (e.g. between 0 and 9 in CIFAR-10)\n",
    "  - W is the weight matrix (e.g. 10 x 3073 in CIFAR-10)\n",
    "  \"\"\"\n",
    "    delta = 1.0 # see notes about delta later in this section\n",
    "    scores = W.dot(x) # scores becomes of size 10 x 1, the scores for each class\n",
    "    correct_class_score = scores[y]\n",
    "    D = W.shape[0] # number of classes, e.g. 10\n",
    "    loss_i = 0.0\n",
    "    for j in xrange(D): # iterate over all wrong classes\n",
    "        if j == y:\n",
    "      # skip for the true class to only loop over incorrect classes\n",
    "          continue\n",
    "    # accumulate loss for the i-th example\n",
    "        loss_i += max(0, scores[j] - correct_class_score + delta)\n",
    "    return loss_i\n",
    "\n",
    "def L_i_vectorized(x, y, W):\n",
    "    \"\"\"\n",
    "    A faster half-vectorized implementation. half-vectorized\n",
    "    refers to the fact that for a single example the implementation contains\n",
    "    no for loops, but there is still one loop over the examples (outside this function)\n",
    "    \"\"\"\n",
    "    delta = 1.0\n",
    "    scores = W.dot(x)\n",
    "    # compute the margins for all classes in one vector operation\n",
    "    margins = np.maximum(0, scores - scores[y] + delta)\n",
    "    # on y-th position scores[y] - scores[y] canceled and gave delta. We want\n",
    "    # to ignore the y-th position and only consider margin on max wrong class\n",
    "    margins[y] = 0\n",
    "    loss_i = np.sum(margins)\n",
    "    return loss_i\n",
    "\n",
    "def L(X, y, W):\n",
    "  \"\"\"\n",
    "  fully-vectorized implementation :\n",
    "  - X holds all the training examples as columns (e.g. 3073 x 50,000 in CIFAR-10)\n",
    "  - y is array of integers specifying correct class (e.g. 50,000-D array)\n",
    "  - W are weights (e.g. 10 x 3073)\n",
    "  \"\"\"\n",
    "  # evaluate loss over all examples in X without using any for loops\n",
    "  # left as exercise to reader in the assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Soft max loss function for multi class `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = np.array([123, 456, 789]) # example with 3 classes and each having large scores\n",
    "p = np.exp(f) / np.sum(np.exp(f)) # Bad: Numeric problem, potential blowup\n",
    "\n",
    "# instead: first shift the values of f so that the highest number is 0:\n",
    "f -= np.max(f) # f becomes [-666, -333, 0]\n",
    "p = np.exp(f) / np.sum(np.exp(f)) # safe to do, gives the correct answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.arange(9).reshape(3,3)*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.arange(3).reshape(1,3)*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 3), (1, 3))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   9.,  441., 1521.]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calc_dist_euc(test, train):\n",
    "    shape_test = test.shape[0]\n",
    "    shape_train = train.shape[0]\n",
    "    distance = np.zeros((shape_test, shape_train))\n",
    "    for u in range(shape_test):\n",
    "        for j in range(shape_train):\n",
    "            distance[u,j] = np.sum(test[u] - train[j])**2\n",
    "    return distance\n",
    "calc_dist_euc(test, train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* end test KNN * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use argsort NP *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2, 3, 4],\n",
       "       [0, 1, 3, 4, 2]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array([[1,2,3,4,5] , [0,2,58,5,5]])\n",
    "np.argsort(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Practical issues: Numeric stability***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you’re writing code for computing the Softmax function in practice, \n",
    "the intermediate terms efyi and ∑jefj may be very large due to the exponentials. \n",
    "Dividing large numbers can be numerically unstable, so it is important to use a normalization trick. \n",
    "Notice that if we multiply the top and bottom of the fraction by a constant C and push it into the sum, we get \n",
    "the following (mathematically equivalent) expression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = np.array([123, 456, 789]) # example with 3 classes and each having large scores\n",
    "p = np.exp(f) / np.sum(np.exp(f)) # Bad: Numeric problem, potential blowup\n",
    "\n",
    "# instead: first shift the values of f so that the highest number is 0:\n",
    "f -= np.max(f) # f becomes [-666, -333, 0]\n",
    "p = np.exp(f) / np.sum(np.exp(f)) # safe to do, gives the correct answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
